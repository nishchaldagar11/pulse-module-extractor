## ğŸ¥ Demo Video

A complete walkthrough of the project implementation, execution, and outputs is available here:

ğŸ‘‰ https://drive.google.com/file/d/1DSf8vVuP9i8ihc7RjRGAEIYCeu8IIyny/view


```text


ğŸ“˜ Pulse - Module Extraction AI Agent
ğŸ“Œ Overview

This project implements an AI-powered documentation module extractor that crawls help-documentation websites and automatically identifies:
  Modules (major product areas)
  Submodules (specific features/actions)
  Descriptions for each module and submodule
  The system processes documentation content only (no external knowledge) and outputs a clean, structured JSON suitable for product and documentation analysis.

ğŸ¯ Objective

To build a scalable, explainable, and deterministic AI agent that can:
   Crawl help documentation URLs
   Infer hierarchical structure (Module â†’ Submodule)
   Generate concise descriptions
    Work across multiple documentation websites in a single run

ğŸ§  High-Level Architecture

URL List
  â†“
Crawler (requests + BeautifulSoup)
  â†“
HTML Cleaner & Section Parser
  â†“
Module & Submodule Inference
  â†“
Rule-Based Summarization
  â†“
Structured JSON Output


## ğŸ“ Project Structure

pulse-module-extractor/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ crawler.py        # Crawls documentation pages
â”‚   â”œâ”€â”€ parser.py         # Cleans HTML and extracts structured sections
â”‚   â”œâ”€â”€ extractor.py      # Infers modules and submodules
â”‚   â”œâ”€â”€ summarizer.py     # Generates concise descriptions
â”‚   â””â”€â”€ utils.py          # Helper utility functions
â”‚
â”œâ”€â”€ output/               # Generated JSON outputs
â”‚
â”œâ”€â”€ app.py                # Entry point (multi-website execution)
â”œâ”€â”€ requirements.txt      # Project dependencies
â””â”€â”€ README.md             # Project documentation


ğŸŒ Supported Documentation Websites (Processed in One Run)

The current configuration processes four documentation websites automatically:

https://help.instagram.com/
https://wordpress.org/documentation/
https://support.neo.space/hc/en-us
https://help.zluri.com/

Each website generates a separate JSON output file.

â–¶ï¸ How to Run

1ï¸âƒ£ Install dependencies
pip install -r requirements.txt

2ï¸âƒ£ Run the application
python app.py

3ï¸âƒ£ Output
After execution, the output/ folder will contain:
output/
â”œâ”€â”€ wordpress_modules.json
â”œâ”€â”€ zluri_modules.json
â”œâ”€â”€ github_modules.json
â”œâ”€â”€ instagram_modules.json
â””â”€â”€ neo_modules.json



ğŸ“„ Sample Output Format
[
  {
    "module": "Account Settings",
    "description": "Features related to managing account credentials, privacy, and preferences.",
    "submodules": {
      "Change Password": "Steps to update the account password securely.",
      "Delete Account": "Instructions for permanently deleting the user account."
    }
  }
]


ğŸ§© Key Design Decisions

1) No topic modeling (LDA / BERTopic)
   Structural inference is used instead for higher accuracy.
2) Explainable logic
   Modules and submodules are derived from HTML heading hierarchy.
3) Deterministic output
   Same input always produces the same output.
4) Scalable pipeline
   Supports multiple websites in a single execution.


âš ï¸ Assumptions
1) Documentation websites use semantic HTML headings (h1, h2, h3)
2) Pages are publicly accessible
3) Content hierarchy reflects product structure


ğŸš§ Limitations
1) Very deep or non-semantic HTML structures may reduce accuracy
2) No multilingual support
3) No JavaScript-rendered content handling
4) - Some documentation websites (e.g., Instagram Help Center, Neo Help Center) rely heavily on
     JavaScript-based rendering. Since this solution uses server-side HTML parsing (requests + BeautifulSoup), such pages may result in limited or empty extraction.



ğŸ› ï¸ Technologies Used
1) Python 3
2) requests
3) BeautifulSoup (bs4)

âœ… Conclusion

This project demonstrates a clean, modular, and production-ready AI agent for extracting structured product intelligence from documentation websites, aligned with real-world product and engineering use cases.










